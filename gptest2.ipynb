{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1ea5647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from MuyGPyS._test.sampler import UnivariateSampler, print_results\n",
    "from MuyGPyS.gp import MuyGPS\n",
    "from MuyGPyS.gp.deformation import Isotropy, l2\n",
    "from MuyGPyS.gp.hyperparameter import AnalyticScale, Parameter\n",
    "from MuyGPyS.gp.kernels import Matern\n",
    "from MuyGPyS.gp.noise import HomoscedasticNoise\n",
    "from MuyGPyS.neighbors import NN_Wrapper\n",
    "from MuyGPyS.optimize import Bayes_optimize\n",
    "from MuyGPyS.optimize.batch import sample_batch\n",
    "from MuyGPyS.optimize.loss import lool_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29ed2ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7381ddbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_count = 3000\n",
    "train_ratio = 0.075\n",
    "\n",
    "nugget_noise = HomoscedasticNoise(1e-14)\n",
    "measurement_noise = HomoscedasticNoise(1e-7)\n",
    "\n",
    "sim_length_scale = Parameter(0.05)\n",
    "sim_smoothness = Parameter(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b142f52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = UnivariateSampler(\n",
    "    data_count=data_count,\n",
    "    train_ratio=train_ratio,\n",
    "    kernel=Matern(\n",
    "        smoothness=sim_smoothness,\n",
    "        deformation=Isotropy(\n",
    "            l2,\n",
    "            length_scale=sim_length_scale,\n",
    "        ),\n",
    "    ),\n",
    "    noise=nugget_noise,\n",
    "    measurement_noise=measurement_noise,\n",
    ")\n",
    "\n",
    "# features are \"x values\", responses are \"f(x)\"\n",
    "train_features, test_features = sampler.features()\n",
    "train_responses, test_responses = sampler.sample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ad285ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 2)\n"
     ]
    }
   ],
   "source": [
    "data = np.stack((train_features, train_responses), axis=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ad10f",
   "metadata": {},
   "source": [
    "Everything above is simply to get data for `train_features`, `test_features`, `train_responses`, and `test_responses` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb3ebd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gp(length, noise):\n",
    "    # Initialize the type of GP to use\n",
    "    # Here we assume noise level and length_scale are known, and optimize for smoothness\n",
    "    gp = MuyGPS(\n",
    "        kernel=Matern(\n",
    "            smoothness=Parameter(\"log_sample\", (0.1, 5.0)),\n",
    "            deformation=Isotropy(\n",
    "                l2,\n",
    "                length_scale=sim_length_scale,\n",
    "            ),\n",
    "        ),\n",
    "        noise=measurement_noise,\n",
    "        scale=AnalyticScale(),\n",
    "    )\n",
    "\n",
    "    return gp\n",
    "\n",
    "def train_gp(gp, batch_indices, batch_nn_indices, data):\n",
    "    (\n",
    "        batch_crosswise_dists,\n",
    "        batch_pairwise_dists,\n",
    "        batch_targets,\n",
    "        batch_nn_targets,\n",
    "    ) = gp.make_train_tensors(\n",
    "        batch_indices,\n",
    "        batch_nn_indices,\n",
    "        data[:,0],\n",
    "        data[:,1],\n",
    "    )\n",
    "\n",
    "    # # Compute covariances for each of the pairwise distances\n",
    "    # Kcross = gp.kernel(batch_crosswise_dists)\n",
    "    # Kin = gp.kernel(batch_pairwise_dists)\n",
    "\n",
    "    # Solve/optimize the GP for best hyperparameters\n",
    "    # We can use scipy.lbfgs here as an alternative\n",
    "    trained_gp = Bayes_optimize(\n",
    "        gp,\n",
    "        batch_targets,\n",
    "        batch_nn_targets,\n",
    "        batch_crosswise_dists,\n",
    "        batch_pairwise_dists,\n",
    "        loss_fn=lool_fn,\n",
    "        verbose=True,\n",
    "        random_state=1,\n",
    "        init_points=5,\n",
    "        n_iter=15,\n",
    "    )\n",
    "\n",
    "    # Optimize scale parameter separately\n",
    "    trained_gp = trained_gp.optimize_scale(batch_pairwise_dists, batch_nn_targets)\n",
    "\n",
    "    return trained_gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4eaf103a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parameters to be optimized: ['smoothness']\n",
      "bounds: [[0.1 5. ]]\n",
      "initial x0: [0.92898658]\n",
      "|   iter    |  target   | smooth... |\n",
      "-------------------------------------\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m1826.4356\u001b[39m | \u001b[39m0.9289865\u001b[39m |\n",
      "| \u001b[35m2        \u001b[39m | \u001b[35m2359.0765\u001b[39m | \u001b[35m2.1434078\u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m1952.6510\u001b[39m | \u001b[39m3.6295900\u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m614.38904\u001b[39m | \u001b[39m0.1005604\u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m2308.5389\u001b[39m | \u001b[39m1.5814296\u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m1707.0528\u001b[39m | \u001b[39m0.8191038\u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m1480.1007\u001b[39m | \u001b[39m5.0      \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m2201.4775\u001b[39m | \u001b[39m2.8303648\u001b[39m |\n",
      "| \u001b[35m9        \u001b[39m | \u001b[35m2373.3739\u001b[39m | \u001b[35m1.8833036\u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m2373.2662\u001b[39m | \u001b[39m1.9964344\u001b[39m |\n",
      "| \u001b[35m11       \u001b[39m | \u001b[35m2374.7103\u001b[39m | \u001b[35m1.9380261\u001b[39m |\n",
      "| \u001b[35m12       \u001b[39m | \u001b[35m2374.7103\u001b[39m | \u001b[35m1.9379595\u001b[39m |\n",
      "| \u001b[35m13       \u001b[39m | \u001b[35m2374.7103\u001b[39m | \u001b[35m1.9378658\u001b[39m |\n",
      "| \u001b[35m14       \u001b[39m | \u001b[35m2374.7103\u001b[39m | \u001b[35m1.9377919\u001b[39m |\n",
      "| \u001b[35m15       \u001b[39m | \u001b[35m2374.7104\u001b[39m | \u001b[35m1.9377218\u001b[39m |\n",
      "| \u001b[35m16       \u001b[39m | \u001b[35m2374.7104\u001b[39m | \u001b[35m1.9376629\u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m2374.7103\u001b[39m | \u001b[39m1.9374795\u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m2374.6874\u001b[39m | \u001b[39m1.9449324\u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m2374.6564\u001b[39m | \u001b[39m1.9265826\u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m2374.6475\u001b[39m | \u001b[39m1.9497154\u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m2374.6505\u001b[39m | \u001b[39m1.9259924\u001b[39m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "# Set up batch of data for training\n",
    "nn_count = 30\n",
    "batch_count = 500\n",
    "\n",
    "nbrs_lookup = NN_Wrapper(train_features, nn_count, nn_method=\"exact\", algorithm=\"ball_tree\")\n",
    "batch_indices, batch_nn_indices = sample_batch(\n",
    "    nbrs_lookup, batch_count, sampler.train_count\n",
    ")\n",
    "\n",
    "gp = create_gp(sim_length_scale, measurement_noise)\n",
    "gp = train_gp(gp, batch_indices, batch_nn_indices, data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b9ba3c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(gp, test_features, train_data):\n",
    "    # Get locations for inference\n",
    "    test_count = test_features.shape[0]\n",
    "    indices = np.arange(test_count)\n",
    "    test_nn_indices, _ = nbrs_lookup.get_nns(test_features)\n",
    "\n",
    "    # Get distance tensors\n",
    "    (\n",
    "        test_crosswise_dists,\n",
    "        test_pairwise_dists,\n",
    "        test_nn_targets,\n",
    "    ) = gp.make_predict_tensors(\n",
    "        indices,\n",
    "        test_nn_indices,\n",
    "        test_features,\n",
    "        train_data[:,0],\n",
    "        train_data[:,1],\n",
    "    )\n",
    "\n",
    "    # Get covariance tensors\n",
    "    Kcross = gp.kernel(test_crosswise_dists)\n",
    "    Kin = gp.kernel(test_pairwise_dists)\n",
    "\n",
    "    # Make prediction\n",
    "    predictions = gp.posterior_mean(Kin, Kcross, test_nn_targets)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cff953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(gp, test_features, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "33d4b80a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Kin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# print results of prediction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m variances = gp.posterior_variance(\u001b[43mKin\u001b[49m, Kcross)\n\u001b[32m      3\u001b[39m confidence_intervals = np.sqrt(variances) * \u001b[32m1.96\u001b[39m\n\u001b[32m      4\u001b[39m coverage = np.count_nonzero(np.abs(test_responses - predictions) < confidence_intervals) / test_count\n",
      "\u001b[31mNameError\u001b[39m: name 'Kin' is not defined"
     ]
    }
   ],
   "source": [
    "# print results of prediction\n",
    "variances = gp.posterior_variance(Kin, Kcross)\n",
    "confidence_intervals = np.sqrt(variances) * 1.96\n",
    "coverage = np.count_nonzero(np.abs(test_responses - predictions) < confidence_intervals) / test_count\n",
    "print_results(\n",
    "    test_responses, (\"optimized\", gp, predictions, variances, confidence_intervals, coverage)\n",
    ")\n",
    "\n",
    "# plot prediction and confidence intervals\n",
    "sampler.plot_results((\"optimized\", predictions, confidence_intervals))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zf-gp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
